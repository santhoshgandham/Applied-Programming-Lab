{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b382263a-4bc3-418d-a36d-1fd9c86bf983",
   "metadata": {},
   "source": [
    "#### Overview of the problem\n",
    "using %timeit we are basically trying to find the various run-times that matmul takes in python and cython\n",
    "by suitable transformations. We obtain inferences from the results by plotting gflops and run-times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfc86c1-8251-4faf-aff6-f989ce83ad1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Step 1\n",
    "import numpy as np\n",
    "# • Construct two numpy matrices of size 10x10 each - the entries should be random numbers.\n",
    "\n",
    "u = np.random.random((10,10))\n",
    "v = np.random.random((10,10))\n",
    "def matrix_multiply(u, v):\n",
    "    m, n = u.shape\n",
    "    n, p = v.shape\n",
    "    res = np.zeros((m, p))\n",
    "    for i in range(m):\n",
    "        for j in range(p):\n",
    "            res[i,j] = 0\n",
    "            for k in range(n):\n",
    "                res[i,j] += u[i,k] * v[k,j]\n",
    "    return res\n",
    "\n",
    "# Use the %timeit special command to find the time required for multiplying the matrices.\n",
    "%timeit matrix_multiply(u, v)\n",
    "# Multiply the same matrices using the u @ v or np.matmul(u, v) notation and measure the time required.\n",
    "%timeit u@v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9232f1b-f444-4b7e-9eb9-3345fd487301",
   "metadata": {},
   "source": [
    "#### Estimate the total number of multiplications required for this matrix computation: \n",
    "1000\n",
    "#### total number of floating point operations: \n",
    "2000\n",
    "#### estimate the GFLOPS: \n",
    "0.0037 GFLOPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b941dc-f7d7-45c8-9982-4a98759e6d4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step2\n",
    "#### Use the lscpu command to find the maximum operating frequency of the CPU on your system:\n",
    "CPU MHz: 2099.998\n",
    "#### Estimate the maximum FLOPS that may be achievable using a single processor core.\n",
    "2.099 GFLOPS\n",
    "#### Comment on how well this compares against the numbers you found in Step 1:\n",
    "On comparison it is clear that the CPU is capable of giving 567 times the number of GFLOPS we got in step1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7450f60a-8a33-401e-bed8-3f4b8f1e9331",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Step3-part1\n",
    "# Repeat step 1, but doubling the matrix sizes for each run.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def matrix_multiply(u, v):\n",
    "    m, n = u.shape\n",
    "    n, p = v.shape\n",
    "    res = np.zeros((m, p))\n",
    "    for i in range(m):\n",
    "        for j in range(p):\n",
    "            res[i,j] = 0\n",
    "            for k in range(n):\n",
    "                res[i,j] += u[i,k] * v[k,j]\n",
    "    return res\n",
    "\n",
    "matrix_size=[]\n",
    "a=[]\n",
    "b=[]\n",
    "for i in range(0,8):\n",
    "    m_s= 2**i\n",
    "    u = np.random.random((2**i,2**i))\n",
    "    v = np.random.random((2**i,2**i))\n",
    "    matrix_size.append(m_s)\n",
    "    a1= %timeit -o -n 1 -r 1 matrix_multiply(u, v)\n",
    "    a.append(a1.best)\n",
    "    b1= %timeit -o -n 1 -r 1 np.matmul(u, v)\n",
    "    b.append(b1.best)\n",
    "\n",
    "# Plot the measured times for the above code as well as the numpy matmul and comment on the results:\n",
    "plt.plot(matrix_size,a,matrix_size,b)\n",
    "plt.xlabel(\"matrix size\")\n",
    "plt.ylabel(\"run time\")\n",
    "plt.show()\n",
    "\n",
    "# do they follow an expected path?\n",
    "'''no'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443373cf-a60f-4c7f-9445-76c09618471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step3-part2\n",
    "# You should be able to run np.matmul for much higher matrix sizes than the above code.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(0,8):\n",
    "    u = np.random.random((100*(2**i),100*(2**i)))\n",
    "    v = np.random.random((100*(2**i),100*(2**i)))\n",
    "    %timeit -o -n 1 -r 1 np.matmul(u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807c5be5-8e8e-441b-9991-99ac79d54aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step3-part3\n",
    "# Plot the estimated GFLOPS from both approaches to matrix multiplication and compare against the theoretical estimates\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def matrix_multiply(u, v):\n",
    "    m, n = u.shape\n",
    "    n, p = v.shape\n",
    "    res = np.zeros((m, p))\n",
    "    for i in range(m):\n",
    "        for j in range(p):\n",
    "            res[i,j] = 0\n",
    "            for k in range(n):\n",
    "                res[i,j] += u[i,k] * v[k,j]\n",
    "    return res\n",
    "\n",
    "matrix_size=[]\n",
    "a=[]\n",
    "b=[]\n",
    "for i in range(0,8):\n",
    "    m_s= 2**i\n",
    "    u = np.random.random((2**i,2**i))\n",
    "    v = np.random.random((2**i,2**i))\n",
    "    matrix_size.append(m_s)\n",
    "    a1= %timeit -o -n 1 -r 1 matrix_multiply(u, v)\n",
    "    a1= ((2**i)**3)/(a1.best*1e9)\n",
    "    a.append(a1)\n",
    "    b1= %timeit -o -n 1 -r 1 np.matmul(u, v)\n",
    "    b1= ((2**i)**3)/(b1.best*1e9)\n",
    "    b.append(b1)\n",
    "\n",
    "plt.plot(matrix_size,a,matrix_size,b)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d7375b2-fc86-480f-bb0f-190dd554be69",
   "metadata": {},
   "source": [
    "### How high are you able to go with this ?(step3-partb)\n",
    "on repeated trial and errors, considering the fact that 40s is a very high run time, a 12,800x12,800 matrix is the highest one upon reaching the 8th iteration of doubling the matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0844b4-eebd-4ea7-9303-120f3c90abad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3754c3-f3fb-4281-8f46-ebd8f8b40472",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "#Step4\n",
    "#Convert the matrix_multiply function to cython. \n",
    "\n",
    "import cython\n",
    "import numpy as np\n",
    "\n",
    "def cy_matmul(u, v, res):\n",
    "    cdef int m, n, p\n",
    "    cdef int i, j, k\n",
    "    m = u.shape[0]\n",
    "    n = u.shape[1]\n",
    "    p = v.shape[1]\n",
    "    # res = np.zeros((m, p))\n",
    "    for i in range(m):\n",
    "        for j in range(p):\n",
    "            res[i,j] = 0\n",
    "            for k in range(n):\n",
    "                res[i,j] += u[i,k] * v[k,j]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a12aa2-8fcd-42f1-98eb-387ce696cfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time it for 50x50 matrices. Compare with the original.\n",
    "u = np.float32(np.random.random((50,50)))\n",
    "v = np.float32(np.random.random((50,50)))\n",
    "res = np.zeros((50, 50), dtype=np.float32)\n",
    "cython_mm= %timeit -o -n 1 -r 1 cy_matmul(u, v, res)\n",
    "print(\"\\n\")\n",
    "print(f\"time for 50x50 matrices for cython in seconds: {cython_mm.best}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ec0316-8eac-4168-8e27-f62ec32b2bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9042c39-bac5-4edf-a5b0-94d59fad33ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "#Step5\n",
    "# On applying each of the following transformations as asked found out that declaring matrices as double[:,:] gave the best optimal time\n",
    "import cython\n",
    "import numpy as np\n",
    "\n",
    "# @cython.boundscheck(False)\n",
    "# @cython.wraparound(False)\n",
    "def cy_matmul(double[:,:] u, double[:,:] v, double[:,:] res):\n",
    "\n",
    "# def cy_matmul(u, v, res):\n",
    "    # cdef int m, n, p\n",
    "    # cdef int i, j, k\n",
    "    m = u.shape[0]\n",
    "    n = u.shape[1]\n",
    "    p = v.shape[1]\n",
    "    res = np.zeros((m, p))\n",
    "    for i in range(m):\n",
    "        for j in range(p):\n",
    "            res[i,j] = 0\n",
    "            for k in range(n):\n",
    "                res[i,j] += u[i,k] * v[k,j]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48f9934-38d0-4211-80a6-b717ee8e4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = np.double(np.random.random((50,50)))\n",
    "v = np.double(np.random.random((50,50)))\n",
    "res = np.zeros((50, 50), dtype=np.double())\n",
    "cython_mm= %timeit -o -n 1 -r 1 cy_matmul(u, v, res)\n",
    "python_mm= %timeit -o -n 1 -r 1 u@v\n",
    "print(\"\\n\")\n",
    "# On applying each of the following transformations as asked found out that declaring matrices as double[:,:] gave the best optimal time\n",
    "print(f\"time for 50x50 matrices for cython in seconds: {cython_mm.best}\\n\")\n",
    "\n",
    "def matrix_multiply(u, v):\n",
    "    m, n = u.shape\n",
    "    n, p = v.shape\n",
    "    res = np.zeros((m, p))\n",
    "    for i in range(m):\n",
    "        for j in range(p):\n",
    "            res[i,j] = 0\n",
    "            for k in range(n):\n",
    "                res[i,j] += u[i,k] * v[k,j]\n",
    "    return res\n",
    "\n",
    "m_m= %timeit -o -q -n 1 -r 1 matrix_multiply(u, v)\n",
    "\n",
    "print(f\"time for 50x50 matrices for python in seconds: {m_m.best}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "418b99a1-fa64-432a-ac2e-bca29527eff6",
   "metadata": {},
   "source": [
    "### Step5\n",
    "#### transformation1:\n",
    "#### • Declare each of the variables i, j, k, m, n, p as int types\n",
    "optimal time: 140ms\n",
    "\n",
    "#### transformation2:\n",
    "#### • Use the decorator function @cython.boundscheck(False). \n",
    "optimal time: 52.7ms\n",
    "#### What does this do?\n",
    "It is used to disable array bounds checking for a specific function or method. \n",
    "By disabling bounds checking, you are telling Cython to assume that the indices \n",
    "you use to access arrays or sequences are always within valid bounds. \n",
    "\n",
    "#### transformation3:\n",
    "#### • Declare the input variables to be of type double[:, :]\n",
    "optimal time: 0.173ms\n",
    "\n",
    "On applying each of the following transformations as asked found out that declaring matrices as double[:,:] gave the best optimal time\n",
    "\n",
    "#### transformation4:\n",
    "#### • Declare res also to be an argument of the function, of the same double[:,:] type, and make sure that res is initialized to a zero array before calling.\n",
    "optimal time: 0.416ms\n",
    "\n",
    "#### transformation5:\n",
    "#### • Change the data type to float[:,:] and repeat the experiments. Does this change anything?\n",
    "optimal time: 0.519ms\n",
    "on finding the type(u[0][0]) we find that it outputs numpy.float64 which clearly tells float is the default datatype."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
